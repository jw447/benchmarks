=====================================================
Mon Mar 25 05:42:48 EDT 2019
--ps_hosts=h09n09:2220
--worker_hosts=h09n09:2221,h09n09:2222,h09n09:2223,h09n09:2224
Parameter setup time: 0.001
Benchmark construction time: 3.216
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:1/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 231.2 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 210.2 +/- 8.0 (jitter = 19.3)	7.869
20	images/sec: 183.5 +/- 10.7 (jitter = 12.1)	7.879
30	images/sec: 194.0 +/- 7.9 (jitter = 11.1)	7.825
40	images/sec: 202.3 +/- 6.1 (jitter = 9.3)	7.966
50	images/sec: 207.7 +/- 4.9 (jitter = 7.8)	7.741
60	images/sec: 211.5 +/- 4.2 (jitter = 7.7)	8.024
70	images/sec: 213.6 +/- 3.6 (jitter = 7.3)	7.775
80	images/sec: 214.3 +/- 3.3 (jitter = 6.9)	7.935
90	images/sec: 214.9 +/- 3.0 (jitter = 6.3)	7.992
100	images/sec: 214.5 +/- 2.8 (jitter = 7.1)	7.982
----------------------------------------------------------------
total images/sec: 857.90
----------------------------------------------------------------
Benchmark run time: 78.325
Parameter setup time: 0.001
Benchmark construction time: 3.220
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:3/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 231.1 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 210.2 +/- 8.0 (jitter = 19.4)	7.869
20	images/sec: 183.5 +/- 10.7 (jitter = 12.0)	7.879
30	images/sec: 194.0 +/- 7.9 (jitter = 10.9)	7.825
40	images/sec: 202.3 +/- 6.1 (jitter = 9.5)	7.966
50	images/sec: 207.7 +/- 4.9 (jitter = 7.7)	7.741
60	images/sec: 211.5 +/- 4.2 (jitter = 7.5)	8.024
70	images/sec: 213.6 +/- 3.6 (jitter = 7.3)	7.775
80	images/sec: 214.3 +/- 3.3 (jitter = 7.1)	7.935
90	images/sec: 214.9 +/- 3.0 (jitter = 6.2)	7.992
100	images/sec: 214.5 +/- 2.8 (jitter = 7.4)	7.982
----------------------------------------------------------------
total images/sec: 857.91
----------------------------------------------------------------
Benchmark run time: 78.336
Parameter setup time: 0.001
Benchmark construction time: 3.213
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:2/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 231.2 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 210.2 +/- 8.0 (jitter = 19.4)	7.869
20	images/sec: 183.6 +/- 10.7 (jitter = 12.2)	7.879
30	images/sec: 194.0 +/- 7.9 (jitter = 11.0)	7.825
40	images/sec: 202.3 +/- 6.1 (jitter = 9.3)	7.966
50	images/sec: 207.7 +/- 4.9 (jitter = 7.7)	7.741
60	images/sec: 211.5 +/- 4.2 (jitter = 7.6)	8.024
70	images/sec: 213.6 +/- 3.6 (jitter = 7.2)	7.775
80	images/sec: 214.3 +/- 3.3 (jitter = 6.9)	7.935
90	images/sec: 214.9 +/- 3.0 (jitter = 6.3)	7.992
100	images/sec: 214.5 +/- 2.8 (jitter = 7.1)	7.982
----------------------------------------------------------------
total images/sec: 857.91
----------------------------------------------------------------
Benchmark run time: 78.360
Parameter setup time: 0.001
Benchmark construction time: 3.212
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 231.2 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 210.2 +/- 8.0 (jitter = 19.2)	7.869
20	images/sec: 183.6 +/- 10.6 (jitter = 11.9)	7.879
30	images/sec: 194.0 +/- 7.8 (jitter = 11.0)	7.825
40	images/sec: 202.3 +/- 6.0 (jitter = 9.4)	7.966
50	images/sec: 207.7 +/- 4.9 (jitter = 7.9)	7.741
60	images/sec: 211.5 +/- 4.1 (jitter = 7.6)	8.024
70	images/sec: 213.6 +/- 3.6 (jitter = 7.1)	7.775
80	images/sec: 214.3 +/- 3.2 (jitter = 6.7)	7.935
90	images/sec: 214.9 +/- 3.0 (jitter = 6.3)	7.992
100	images/sec: 214.5 +/- 2.8 (jitter = 7.2)	7.959
----------------------------------------------------------------
total images/sec: 857.91
----------------------------------------------------------------
Benchmark run time: 78.389

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch5>
Subject: Job 307180: <n1_ps_4w_g1_e100> in cluster <summit> Exited

Job <n1_ps_4w_g1_e100> was submitted from host <login2> by user <jw447> in cluster <summit> at Mon Mar 25 02:39:16 2019
Job was executed on host(s) <1*batch5>, in queue <batch>, as user <jw447> in cluster <summit> at Mon Mar 25 05:42:45 2019
                            <42*h09n09>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/summit/ps> was used as the working directory.
Started at Mon Mar 25 05:42:45 2019
Terminated at Mon Mar 25 06:12:54 2019
Results reported at Mon Mar 25 06:12:54 2019

The output (if any) is above this job summary.



PS:

Read file <n1_ps_4w_g1_e100.e> for stderr output of this job.

=====================================================
Mon Mar 25 06:13:32 EDT 2019
--ps_hosts=h28n11:2220
--worker_hosts=h28n11:2221,h28n11:2222,h28n11:2223,h28n11:2224
Parameter setup time: 0.001
Benchmark construction time: 3.441
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:1/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 232.0 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 228.3 +/- 1.7 (jitter = 3.1)	7.867
20	images/sec: 231.2 +/- 1.7 (jitter = 7.8)	7.874
30	images/sec: 231.7 +/- 1.5 (jitter = 6.7)	7.847
40	images/sec: 228.0 +/- 2.0 (jitter = 7.8)	7.965
50	images/sec: 228.1 +/- 2.0 (jitter = 7.0)	7.729
60	images/sec: 228.5 +/- 1.7 (jitter = 7.0)	8.033
70	images/sec: 227.2 +/- 1.7 (jitter = 7.5)	7.775
80	images/sec: 227.6 +/- 1.5 (jitter = 7.1)	7.909
90	images/sec: 227.8 +/- 1.4 (jitter = 7.2)	8.026
100	images/sec: 228.0 +/- 1.3 (jitter = 7.1)	7.977
----------------------------------------------------------------
total images/sec: 911.58
----------------------------------------------------------------
Benchmark run time: 76.892
Parameter setup time: 0.001
Benchmark construction time: 3.448
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:2/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 232.2 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 228.3 +/- 1.7 (jitter = 2.9)	7.867
20	images/sec: 231.2 +/- 1.7 (jitter = 7.7)	7.874
30	images/sec: 231.7 +/- 1.5 (jitter = 6.8)	7.847
40	images/sec: 228.0 +/- 2.0 (jitter = 7.9)	7.965
50	images/sec: 228.1 +/- 2.0 (jitter = 7.1)	7.729
60	images/sec: 228.5 +/- 1.7 (jitter = 7.1)	8.033
70	images/sec: 227.2 +/- 1.7 (jitter = 7.4)	7.775
80	images/sec: 227.6 +/- 1.5 (jitter = 7.2)	7.909
90	images/sec: 227.8 +/- 1.4 (jitter = 7.4)	8.026
100	images/sec: 228.0 +/- 1.3 (jitter = 7.3)	7.977
----------------------------------------------------------------
total images/sec: 911.58
----------------------------------------------------------------
Benchmark run time: 76.902
Parameter setup time: 0.001
Benchmark construction time: 3.442
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:3/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 232.3 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 228.4 +/- 1.7 (jitter = 3.0)	7.867
20	images/sec: 231.2 +/- 1.7 (jitter = 7.7)	7.874
30	images/sec: 231.7 +/- 1.5 (jitter = 6.7)	7.847
40	images/sec: 228.0 +/- 2.0 (jitter = 8.1)	7.965
50	images/sec: 228.1 +/- 2.0 (jitter = 7.0)	7.729
60	images/sec: 228.5 +/- 1.7 (jitter = 7.0)	8.033
70	images/sec: 227.2 +/- 1.7 (jitter = 7.3)	7.775
80	images/sec: 227.6 +/- 1.5 (jitter = 7.2)	7.909
90	images/sec: 227.8 +/- 1.4 (jitter = 7.4)	8.026
100	images/sec: 228.0 +/- 1.3 (jitter = 7.2)	7.977
----------------------------------------------------------------
total images/sec: 911.58
----------------------------------------------------------------
Benchmark run time: 76.926
Parameter setup time: 0.001
Benchmark construction time: 3.435
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 232.2 +/- 0.0 (jitter = 0.0)	8.210
10	images/sec: 228.4 +/- 1.7 (jitter = 3.0)	7.867
20	images/sec: 231.2 +/- 1.7 (jitter = 7.6)	7.874
30	images/sec: 231.7 +/- 1.5 (jitter = 6.5)	7.847
40	images/sec: 228.0 +/- 2.0 (jitter = 7.9)	7.965
50	images/sec: 228.1 +/- 2.0 (jitter = 6.9)	7.729
60	images/sec: 228.5 +/- 1.7 (jitter = 6.8)	8.033
70	images/sec: 227.2 +/- 1.7 (jitter = 7.3)	7.775
80	images/sec: 227.6 +/- 1.5 (jitter = 7.0)	7.909
90	images/sec: 227.8 +/- 1.4 (jitter = 7.2)	8.026
100	images/sec: 228.0 +/- 1.3 (jitter = 7.1)	7.977
----------------------------------------------------------------
total images/sec: 911.58
----------------------------------------------------------------
Benchmark run time: 76.964

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch5>
Subject: Job 307181: <n1_ps_4w_g1_e100> in cluster <summit> Exited

Job <n1_ps_4w_g1_e100> was submitted from host <login2> by user <jw447> in cluster <summit> at Mon Mar 25 02:39:17 2019
Job was executed on host(s) <1*batch5>, in queue <batch>, as user <jw447> in cluster <summit> at Mon Mar 25 06:13:29 2019
                            <42*h28n11>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/summit/ps> was used as the working directory.
Started at Mon Mar 25 06:13:29 2019
Terminated at Mon Mar 25 06:43:40 2019
Results reported at Mon Mar 25 06:43:40 2019

The output (if any) is above this job summary.



PS:

Read file <n1_ps_4w_g1_e100.e> for stderr output of this job.

=====================================================
Mon Mar 25 06:44:19 EDT 2019
--ps_hosts=h28n11:2220
--worker_hosts=h28n11:2221,h28n11:2222,h28n11:2223,h28n11:2224
Parameter setup time: 0.001
Benchmark construction time: 3.296
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:3/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 222.5 +/- 0.0 (jitter = 0.0)	8.211
10	images/sec: 230.6 +/- 2.3 (jitter = 10.6)	7.874
20	images/sec: 229.5 +/- 1.8 (jitter = 5.8)	7.888
30	images/sec: 229.7 +/- 1.4 (jitter = 5.5)	7.824
40	images/sec: 229.2 +/- 1.4 (jitter = 4.9)	7.964
50	images/sec: 226.5 +/- 2.3 (jitter = 4.6)	7.736
60	images/sec: 227.0 +/- 1.9 (jitter = 4.2)	8.066
70	images/sec: 226.9 +/- 1.7 (jitter = 4.3)	7.797
80	images/sec: 227.9 +/- 1.5 (jitter = 4.5)	7.951
90	images/sec: 227.9 +/- 1.4 (jitter = 4.7)	8.047
100	images/sec: 227.5 +/- 1.3 (jitter = 5.3)	7.972
----------------------------------------------------------------
total images/sec: 909.68
----------------------------------------------------------------
Benchmark run time: 74.768
Parameter setup time: 0.001
Benchmark construction time: 3.297
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 222.7 +/- 0.0 (jitter = 0.0)	8.211
10	images/sec: 230.6 +/- 2.3 (jitter = 10.8)	7.874
20	images/sec: 229.5 +/- 1.8 (jitter = 5.8)	7.888
30	images/sec: 229.7 +/- 1.4 (jitter = 5.5)	7.824
40	images/sec: 229.2 +/- 1.4 (jitter = 4.9)	7.964
50	images/sec: 226.5 +/- 2.3 (jitter = 4.6)	7.736
60	images/sec: 227.0 +/- 1.9 (jitter = 4.4)	8.066
70	images/sec: 227.0 +/- 1.7 (jitter = 4.3)	7.797
80	images/sec: 227.9 +/- 1.5 (jitter = 4.4)	7.951
90	images/sec: 227.9 +/- 1.4 (jitter = 4.5)	8.047
100	images/sec: 227.5 +/- 1.3 (jitter = 5.2)	7.972
----------------------------------------------------------------
total images/sec: 909.67
----------------------------------------------------------------
Benchmark run time: 74.800
Parameter setup time: 0.001
Benchmark construction time: 3.295
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:2/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 222.7 +/- 0.0 (jitter = 0.0)	8.211
10	images/sec: 230.6 +/- 2.3 (jitter = 10.7)	7.874
20	images/sec: 229.5 +/- 1.8 (jitter = 5.8)	7.888
30	images/sec: 229.7 +/- 1.4 (jitter = 5.6)	7.824
40	images/sec: 229.2 +/- 1.4 (jitter = 4.9)	7.964
50	images/sec: 226.5 +/- 2.3 (jitter = 4.7)	7.736
60	images/sec: 227.0 +/- 1.9 (jitter = 4.4)	8.066
70	images/sec: 226.9 +/- 1.7 (jitter = 4.5)	7.797
80	images/sec: 227.9 +/- 1.5 (jitter = 4.5)	7.951
90	images/sec: 227.9 +/- 1.4 (jitter = 4.5)	8.047
100	images/sec: 227.5 +/- 1.3 (jitter = 5.3)	7.972
----------------------------------------------------------------
total images/sec: 909.68
----------------------------------------------------------------
Benchmark run time: 74.809
Parameter setup time: 0.001
Benchmark construction time: 3.281
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  256 global
             64 per device
Num batches: 100
Num epochs:  0.02
Devices:     ['/job:worker/replica:0/task:1/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 222.9 +/- 0.0 (jitter = 0.0)	8.211
10	images/sec: 230.6 +/- 2.3 (jitter = 10.9)	7.874
20	images/sec: 229.5 +/- 1.8 (jitter = 5.8)	7.888
30	images/sec: 229.7 +/- 1.4 (jitter = 5.5)	7.824
40	images/sec: 229.2 +/- 1.4 (jitter = 4.9)	7.964
50	images/sec: 226.5 +/- 2.3 (jitter = 4.6)	7.736
60	images/sec: 227.0 +/- 1.9 (jitter = 4.3)	8.066
70	images/sec: 226.9 +/- 1.7 (jitter = 4.6)	7.797
80	images/sec: 227.9 +/- 1.5 (jitter = 4.4)	7.951
90	images/sec: 227.9 +/- 1.4 (jitter = 4.7)	8.047
100	images/sec: 227.5 +/- 1.3 (jitter = 5.6)	7.972
----------------------------------------------------------------
total images/sec: 909.68
----------------------------------------------------------------
Benchmark run time: 74.848

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch3>
Subject: Job 307182: <n1_ps_4w_g1_e100> in cluster <summit> Exited

Job <n1_ps_4w_g1_e100> was submitted from host <login2> by user <jw447> in cluster <summit> at Mon Mar 25 02:39:17 2019
Job was executed on host(s) <1*batch3>, in queue <batch>, as user <jw447> in cluster <summit> at Mon Mar 25 06:44:16 2019
                            <42*h28n11>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/summit/ps> was used as the working directory.
Started at Mon Mar 25 06:44:16 2019
Terminated at Mon Mar 25 07:14:33 2019
Results reported at Mon Mar 25 07:14:33 2019

The output (if any) is above this job summary.



PS:

Read file <n1_ps_4w_g1_e100.e> for stderr output of this job.

