=====================================================
Thu Mar 21 11:37:47 EDT 2019
--ps_hosts=h36n12:2220
--worker_hosts=h36n12:2221,h36n13:2222,h36n15:2223,h36n16:2224
Parameter setup time: 0.001
Benchmark construction time: 7.641
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:3/gpu:0', '/job:worker/replica:0/task:3/gpu:1', '/job:worker/replica:0/task:3/gpu:2', '/job:worker/replica:0/task:3/gpu:3', '/job:worker/replica:0/task:3/gpu:4', '/job:worker/replica:0/task:3/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 97.8 +/- 0.0 (jitter = 0.0)	7.885
10	images/sec: 101.8 +/- 1.5 (jitter = 3.1)	7.876
20	images/sec: 97.5 +/- 2.0 (jitter = 5.0)	7.752
30	images/sec: 97.9 +/- 1.6 (jitter = 5.2)	7.799
40	images/sec: 97.5 +/- 1.4 (jitter = 6.7)	7.693
50	images/sec: 96.8 +/- 1.4 (jitter = 6.3)	7.588
60	images/sec: 97.3 +/- 1.3 (jitter = 5.7)	7.557
70	images/sec: 97.0 +/- 1.2 (jitter = 5.8)	7.523
80	images/sec: 96.4 +/- 1.2 (jitter = 6.2)	7.508
90	images/sec: 96.2 +/- 1.1 (jitter = 6.7)	7.496
100	images/sec: 96.3 +/- 1.0 (jitter = 7.1)	7.489
----------------------------------------------------------------
total images/sec: 385.15
----------------------------------------------------------------
Benchmark run time: 561.633
Parameter setup time: 0.001
Benchmark construction time: 7.878
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:2/gpu:0', '/job:worker/replica:0/task:2/gpu:1', '/job:worker/replica:0/task:2/gpu:2', '/job:worker/replica:0/task:2/gpu:3', '/job:worker/replica:0/task:2/gpu:4', '/job:worker/replica:0/task:2/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 97.8 +/- 0.0 (jitter = 0.0)	7.885
10	images/sec: 101.8 +/- 1.6 (jitter = 3.1)	7.876
20	images/sec: 97.5 +/- 2.0 (jitter = 5.0)	7.752
30	images/sec: 97.9 +/- 1.6 (jitter = 5.2)	7.799
40	images/sec: 97.5 +/- 1.4 (jitter = 6.7)	7.693
50	images/sec: 96.8 +/- 1.4 (jitter = 6.3)	7.588
60	images/sec: 97.3 +/- 1.3 (jitter = 5.7)	7.557
70	images/sec: 97.0 +/- 1.2 (jitter = 5.8)	7.523
80	images/sec: 96.4 +/- 1.2 (jitter = 6.2)	7.508
90	images/sec: 96.2 +/- 1.1 (jitter = 6.6)	7.496
100	images/sec: 96.3 +/- 1.0 (jitter = 7.1)	7.489
----------------------------------------------------------------
total images/sec: 385.15
----------------------------------------------------------------
Benchmark run time: 564.233
Parameter setup time: 0.001
Benchmark construction time: 7.746
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:0/gpu:0', '/job:worker/replica:0/task:0/gpu:1', '/job:worker/replica:0/task:0/gpu:2', '/job:worker/replica:0/task:0/gpu:3', '/job:worker/replica:0/task:0/gpu:4', '/job:worker/replica:0/task:0/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 97.8 +/- 0.0 (jitter = 0.0)	7.885
10	images/sec: 101.8 +/- 1.6 (jitter = 3.1)	7.876
20	images/sec: 97.5 +/- 2.0 (jitter = 5.0)	7.752
30	images/sec: 97.9 +/- 1.6 (jitter = 5.2)	7.799
40	images/sec: 97.5 +/- 1.4 (jitter = 6.7)	7.693
50	images/sec: 96.8 +/- 1.4 (jitter = 6.3)	7.588
60	images/sec: 97.3 +/- 1.3 (jitter = 5.7)	7.557
70	images/sec: 97.0 +/- 1.2 (jitter = 5.8)	7.523
80	images/sec: 96.4 +/- 1.2 (jitter = 6.2)	7.508
90	images/sec: 96.2 +/- 1.1 (jitter = 6.7)	7.496
100	images/sec: 96.3 +/- 1.0 (jitter = 7.1)	7.489
----------------------------------------------------------------
total images/sec: 385.15
----------------------------------------------------------------
Benchmark run time: 564.426
Parameter setup time: 0.001
Benchmark construction time: 7.862
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:1/gpu:0', '/job:worker/replica:0/task:1/gpu:1', '/job:worker/replica:0/task:1/gpu:2', '/job:worker/replica:0/task:1/gpu:3', '/job:worker/replica:0/task:1/gpu:4', '/job:worker/replica:0/task:1/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 97.8 +/- 0.0 (jitter = 0.0)	7.885
10	images/sec: 101.8 +/- 1.6 (jitter = 3.1)	7.876
20	images/sec: 97.5 +/- 2.0 (jitter = 5.0)	7.752
30	images/sec: 97.9 +/- 1.6 (jitter = 5.2)	7.799
40	images/sec: 97.5 +/- 1.4 (jitter = 6.7)	7.693
50	images/sec: 96.8 +/- 1.4 (jitter = 6.3)	7.588
60	images/sec: 97.3 +/- 1.3 (jitter = 5.7)	7.557
70	images/sec: 97.0 +/- 1.2 (jitter = 5.8)	7.523
80	images/sec: 96.4 +/- 1.2 (jitter = 6.2)	7.508
90	images/sec: 96.2 +/- 1.1 (jitter = 6.6)	7.496
100	images/sec: 96.3 +/- 1.0 (jitter = 7.1)	7.489
----------------------------------------------------------------
total images/sec: 385.15
----------------------------------------------------------------
Benchmark run time: 564.263

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch2>
Subject: Job 304296: <n4_dr_4w_g6_e100> in cluster <summit> Exited

Job <n4_dr_4w_g6_e100> was submitted from host <login1> by user <jw447> in cluster <summit> at Thu Mar 21 01:48:30 2019
Job was executed on host(s) <1*batch2>, in queue <batch>, as user <jw447> in cluster <summit> at Thu Mar 21 11:37:41 2019
                            <42*h36n12>
                            <42*h36n13>
                            <42*h36n15>
                            <42*h36n16>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/run_summit> was used as the working directory.
Started at Thu Mar 21 11:37:41 2019
Terminated at Thu Mar 21 12:07:52 2019
Results reported at Thu Mar 21 12:07:52 2019

The output (if any) is above this job summary.



PS:

Read file <n4_dr_4w_g6_e100.e> for stderr output of this job.

=====================================================
Sun Mar 24 21:00:19 EDT 2019
--ps_hosts=h35n10:2220
--worker_hosts=h35n10:2221,h35n11:2222,h35n12:2223,h35n15:2224
Parameter setup time: 0.001
Benchmark construction time: 7.588
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:2/gpu:0', '/job:worker/replica:0/task:2/gpu:1', '/job:worker/replica:0/task:2/gpu:2', '/job:worker/replica:0/task:2/gpu:3', '/job:worker/replica:0/task:2/gpu:4', '/job:worker/replica:0/task:2/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 94.7 +/- 0.0 (jitter = 0.0)	7.896
10	images/sec: 90.9 +/- 2.0 (jitter = 3.9)	7.860
20	images/sec: 91.0 +/- 1.6 (jitter = 3.6)	7.756
30	images/sec: 91.2 +/- 1.2 (jitter = 3.7)	7.791
40	images/sec: 91.6 +/- 1.1 (jitter = 4.0)	7.679
50	images/sec: 91.2 +/- 1.0 (jitter = 3.6)	7.590
60	images/sec: 91.2 +/- 0.9 (jitter = 4.0)	7.563
70	images/sec: 90.7 +/- 0.9 (jitter = 4.6)	7.525
80	images/sec: 90.2 +/- 0.9 (jitter = 4.8)	7.494
90	images/sec: 90.2 +/- 0.8 (jitter = 5.2)	7.496
100	images/sec: 90.5 +/- 0.8 (jitter = 4.9)	7.486
----------------------------------------------------------------
total images/sec: 361.91
----------------------------------------------------------------
Benchmark run time: 588.730
Parameter setup time: 0.001
Benchmark construction time: 7.821
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:0/gpu:0', '/job:worker/replica:0/task:0/gpu:1', '/job:worker/replica:0/task:0/gpu:2', '/job:worker/replica:0/task:0/gpu:3', '/job:worker/replica:0/task:0/gpu:4', '/job:worker/replica:0/task:0/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 94.6 +/- 0.0 (jitter = 0.0)	7.896
10	images/sec: 90.9 +/- 2.0 (jitter = 3.9)	7.860
20	images/sec: 91.0 +/- 1.6 (jitter = 3.6)	7.756
30	images/sec: 91.2 +/- 1.2 (jitter = 3.8)	7.791
40	images/sec: 91.6 +/- 1.1 (jitter = 4.0)	7.679
50	images/sec: 91.2 +/- 1.0 (jitter = 3.7)	7.590
60	images/sec: 91.2 +/- 0.9 (jitter = 4.0)	7.563
70	images/sec: 90.7 +/- 0.9 (jitter = 4.6)	7.525
80	images/sec: 90.2 +/- 0.9 (jitter = 4.8)	7.494
90	images/sec: 90.2 +/- 0.8 (jitter = 5.2)	7.496
100	images/sec: 90.5 +/- 0.8 (jitter = 4.9)	7.486
----------------------------------------------------------------
total images/sec: 361.91
----------------------------------------------------------------
Benchmark run time: 588.487
Parameter setup time: 0.001
Benchmark construction time: 7.828
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:1/gpu:0', '/job:worker/replica:0/task:1/gpu:1', '/job:worker/replica:0/task:1/gpu:2', '/job:worker/replica:0/task:1/gpu:3', '/job:worker/replica:0/task:1/gpu:4', '/job:worker/replica:0/task:1/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 94.6 +/- 0.0 (jitter = 0.0)	7.896
10	images/sec: 90.9 +/- 2.0 (jitter = 3.9)	7.860
20	images/sec: 91.0 +/- 1.6 (jitter = 3.6)	7.756
30	images/sec: 91.2 +/- 1.2 (jitter = 3.8)	7.791
40	images/sec: 91.6 +/- 1.1 (jitter = 4.0)	7.679
50	images/sec: 91.2 +/- 1.0 (jitter = 3.6)	7.590
60	images/sec: 91.2 +/- 0.9 (jitter = 4.0)	7.563
70	images/sec: 90.7 +/- 0.9 (jitter = 4.6)	7.525
80	images/sec: 90.2 +/- 0.9 (jitter = 4.8)	7.494
90	images/sec: 90.2 +/- 0.8 (jitter = 5.2)	7.496
100	images/sec: 90.5 +/- 0.8 (jitter = 4.9)	7.486
----------------------------------------------------------------
total images/sec: 361.91
----------------------------------------------------------------
Benchmark run time: 588.491
Parameter setup time: 0.001
Benchmark construction time: 7.840
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  1536 global
             64 per device
Num batches: 100
Num epochs:  0.12
Devices:     ['/job:worker/replica:0/task:3/gpu:0', '/job:worker/replica:0/task:3/gpu:1', '/job:worker/replica:0/task:3/gpu:2', '/job:worker/replica:0/task:3/gpu:3', '/job:worker/replica:0/task:3/gpu:4', '/job:worker/replica:0/task:3/gpu:5']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 94.6 +/- 0.0 (jitter = 0.0)	7.896
10	images/sec: 90.9 +/- 2.0 (jitter = 3.9)	7.860
20	images/sec: 91.0 +/- 1.6 (jitter = 3.6)	7.756
30	images/sec: 91.2 +/- 1.2 (jitter = 3.8)	7.791
40	images/sec: 91.6 +/- 1.1 (jitter = 4.0)	7.679
50	images/sec: 91.2 +/- 1.0 (jitter = 3.7)	7.590
60	images/sec: 91.2 +/- 0.9 (jitter = 4.0)	7.563
70	images/sec: 90.7 +/- 0.9 (jitter = 4.6)	7.525
80	images/sec: 90.2 +/- 0.9 (jitter = 4.8)	7.494
90	images/sec: 90.2 +/- 0.8 (jitter = 5.2)	7.496
100	images/sec: 90.5 +/- 0.8 (jitter = 4.9)	7.486
----------------------------------------------------------------
total images/sec: 361.91
----------------------------------------------------------------
Benchmark run time: 587.922

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch4>
Subject: Job 306981: <n4_dr_4w_g6_e100> in cluster <summit> Exited

Job <n4_dr_4w_g6_e100> was submitted from host <login1> by user <jw447> in cluster <summit> at Sun Mar 24 19:42:57 2019
Job was executed on host(s) <1*batch4>, in queue <batch>, as user <jw447> in cluster <summit> at Sun Mar 24 21:00:15 2019
                            <42*h35n10>
                            <42*h35n11>
                            <42*h35n12>
                            <42*h35n15>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/summit/dist_rep> was used as the working directory.
Started at Sun Mar 24 21:00:15 2019
Terminated at Sun Mar 24 21:20:35 2019
Results reported at Sun Mar 24 21:20:35 2019

The output (if any) is above this job summary.



PS:

Read file <n4_dr_4w_g6_e100.e> for stderr output of this job.

