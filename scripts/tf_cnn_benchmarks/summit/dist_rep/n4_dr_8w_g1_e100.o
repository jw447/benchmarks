=====================================================
Fri Mar 22 15:22:12 EDT 2019
--ps_hosts=a03n13:2220
--worker_hosts=a03n13:2221,a03n16:2222,a03n16:2223,c07n02:2224,c07n02:2225,c07n03:2226,c07n03:2227,a03n13:2228
Parameter setup time: 0.001
Benchmark construction time: 1.894
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:2/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 938.098
Parameter setup time: 0.001
Benchmark construction time: 1.922
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:5/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 938.107
Parameter setup time: 0.001
Benchmark construction time: 1.916
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:6/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 938.153
Parameter setup time: 0.001
Benchmark construction time: 1.900
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:1/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 938.204
Parameter setup time: 0.001
Benchmark construction time: 1.835
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:4/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 937.265
Parameter setup time: 0.001
Benchmark construction time: 1.785
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:7/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 943.410
Parameter setup time: 0.001
Benchmark construction time: 1.779
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 943.459
Parameter setup time: 0.001
Benchmark construction time: 1.825
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:3/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 7.7 +/- 0.0 (jitter = 0.0)	8.189
10	images/sec: 7.7 +/- 0.1 (jitter = 0.2)	7.873
20	images/sec: 7.8 +/- 0.1 (jitter = 0.4)	7.878
30	images/sec: 7.8 +/- 0.1 (jitter = 0.3)	7.768
40	images/sec: 7.9 +/- 0.1 (jitter = 0.3)	7.936
50	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.728
60	images/sec: 7.9 +/- 0.1 (jitter = 0.4)	7.965
70	images/sec: 7.9 +/- 0.0 (jitter = 0.4)	7.734
80	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.809
90	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.901
100	images/sec: 7.9 +/- 0.0 (jitter = 0.5)	7.881
----------------------------------------------------------------
total images/sec: 63.51
----------------------------------------------------------------
Benchmark run time: 937.393

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch1>
Subject: Job 305763: <n4_dr_8w_g1_e100> in cluster <summit> Exited

Job <n4_dr_8w_g1_e100> was submitted from host <login2> by user <jw447> in cluster <summit> at Fri Mar 22 15:22:06 2019
Job was executed on host(s) <1*batch1>, in queue <batch>, as user <jw447> in cluster <summit> at Fri Mar 22 15:22:08 2019
                            <42*a03n13>
                            <42*a03n16>
                            <42*c07n02>
                            <42*c07n03>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/run_summit/distributed_replicated> was used as the working directory.
Started at Fri Mar 22 15:22:08 2019
Terminated at Fri Mar 22 15:42:14 2019
Results reported at Fri Mar 22 15:42:14 2019

The output (if any) is above this job summary.



PS:

Read file <n4_dr_8w_g1_e100.e> for stderr output of this job.

