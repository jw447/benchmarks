=====================================================
Thu Mar 21 12:08:27 EDT 2019
--ps_hosts=h17n11:2220
--worker_hosts=h17n11:2221,h17n11:2222,h17n11:2223,h17n11:2224,h17n11:2225,h17n12:2226,h17n12:2227,h17n12:2228
Parameter setup time: 0.001
Benchmark construction time: 2.514
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:6/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 446.863
Parameter setup time: 0.001
Benchmark construction time: 4.078
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:3/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 445.335
Parameter setup time: 0.001
Benchmark construction time: 4.065
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:4/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 445.387
Parameter setup time: 0.001
Benchmark construction time: 2.522
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:5/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 446.968
Parameter setup time: 0.001
Benchmark construction time: 4.069
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:1/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 445.465
Parameter setup time: 0.001
Benchmark construction time: 4.069
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:2/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 445.497
Parameter setup time: 0.001
Benchmark construction time: 2.512
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:7/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 447.093
Parameter setup time: 0.001
Benchmark construction time: 4.065
TensorFlow:  1.13
Model:       resnet50
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  512 global
             64 per device
Num batches: 100
Num epochs:  0.04
Devices:     ['/job:worker/replica:0/task:0/gpu:0']
NUMA bind:   False
Data format: NCHW
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
==========
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 19.4 +/- 0.0 (jitter = 0.0)	8.187
10	images/sec: 17.7 +/- 0.6 (jitter = 2.0)	7.863
20	images/sec: 18.1 +/- 0.4 (jitter = 1.3)	7.874
30	images/sec: 18.2 +/- 0.3 (jitter = 1.2)	7.791
40	images/sec: 18.2 +/- 0.3 (jitter = 1.5)	7.915
50	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.744
60	images/sec: 18.3 +/- 0.2 (jitter = 1.5)	7.955
70	images/sec: 18.3 +/- 0.2 (jitter = 1.4)	7.735
80	images/sec: 18.4 +/- 0.2 (jitter = 1.4)	7.836
90	images/sec: 18.4 +/- 0.1 (jitter = 1.4)	7.937
100	images/sec: 18.3 +/- 0.1 (jitter = 1.4)	7.852
----------------------------------------------------------------
total images/sec: 146.05
----------------------------------------------------------------
Benchmark run time: 445.589

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch1>
Subject: Job 304298: <n2_dr_8w_g1_e100> in cluster <summit> Exited

Job <n2_dr_8w_g1_e100> was submitted from host <login1> by user <jw447> in cluster <summit> at Thu Mar 21 01:49:51 2019
Job was executed on host(s) <1*batch1>, in queue <batch>, as user <jw447> in cluster <summit> at Thu Mar 21 12:08:22 2019
                            <42*h17n11>
                            <42*h17n12>
</ccs/home/jw447> was used as the home directory.
</gpfs/alpine/proj-shared/csc143/jwang/benchmarks/scripts/tf_cnn_benchmarks/run_summit> was used as the working directory.
Started at Thu Mar 21 12:08:22 2019
Terminated at Thu Mar 21 12:41:02 2019
Results reported at Thu Mar 21 12:41:02 2019

The output (if any) is above this job summary.



PS:

Read file <n2_dr_8w_g1_e100.e> for stderr output of this job.

